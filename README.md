

#output
![Screenshot 2025-04-21 113057](https://github.com/user-attachments/assets/450e3e80-028f-4a93-a0fd-b7880e663f73)

• Developed a machine learning code using a Bi-directional LSTM model to classify comments as ”Toxic” or ”Not Toxic”,
 achieving 96.4% accuracy.
 • Allowed users to input comments manually or upload a CSV file to batch process multiple comments and save the results


